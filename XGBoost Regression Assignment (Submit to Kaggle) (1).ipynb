{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is inspired by: \n",
    "\n",
    "- https://www.kaggle.com/code/carlmcbrideellis/an-introduction-to-xgboost-regression\n",
    "- https://www.kaggle.com/code/dansbecker/xgboost/notebook\n",
    "\n",
    "In this assignment we will apply XGBoost Regression techniques to predict house prices, based on the famous Kaggle Dataset https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
    "\n",
    "Step 1 is to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:49:03.875064Z",
     "iopub.status.busy": "2022-10-17T08:49:03.874451Z",
     "iopub.status.idle": "2022-10-17T08:49:03.951957Z",
     "shell.execute_reply": "2022-10-17T08:49:03.950940Z",
     "shell.execute_reply.started": "2022-10-17T08:49:03.874981Z"
    }
   },
   "outputs": [],
   "source": [
    "#=========================================================================\n",
    "# load up the libraries\n",
    "#=========================================================================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Change settings for viewing records \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#=========================================================================\n",
    "# read in the data\n",
    "#=========================================================================\n",
    "train_data = pd.read_csv('train.csv',index_col=0)\n",
    "test_data  = pd.read_csv('test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Exploration, Selection and Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Validate Set: 1002922309.9236392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Explore the data \n",
    "\n",
    "# print(train_data.head())\n",
    "# print(train_data.info())\n",
    "# print(train_data.describe())\n",
    "\n",
    "# Divide into train and validate (80 train and 20 validate)\n",
    "train_df, validate_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Drop columns with missing values > 10%\n",
    "missing_threshold = 0.1 * len(train_df)\n",
    "train_df = train_df.dropna(thresh=missing_threshold, axis=1)\n",
    "validate_df = validate_df[train_df.columns]\n",
    "\n",
    "\n",
    "# Retain columns that are statistically significant (T-test for categorical columns and correlation for numerical columns)\n",
    "# T-test for categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include='object').columns\n",
    "significant_categorical_cols = []\n",
    "for col in categorical_cols:\n",
    "    t_stat, p_value = stats.ttest_ind(train_df[train_df['SalePrice'] == 0][col], train_df[train_df['SalePrice'] == 1][col])\n",
    "    if p_value < 0.05:\n",
    "        significant_categorical_cols.append(col)\n",
    "\n",
    "\n",
    "\n",
    "# Correlation for numerical columns\n",
    "numerical_cols = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "corr_matrix = train_df[numerical_cols].corr()\n",
    "significant_numerical_cols = [col for col in numerical_cols if abs(corr_matrix['SalePrice'][col]) > 0.1]\n",
    "\n",
    "significant_cols = significant_categorical_cols + significant_numerical_cols\n",
    "\n",
    "\n",
    "train_df = train_df[significant_cols]\n",
    "validate_df = validate_df[significant_cols]\n",
    "\n",
    "# # Separate features and target variable\n",
    "X_train = train_df.drop('SalePrice', axis=1)\n",
    "y_train = train_df[['SalePrice']]\n",
    "X_validate = validate_df.drop('SalePrice', axis=1)\n",
    "y_validate = validate_df[['SalePrice']]\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the validate set\n",
    "y_pred = xgb_model.predict(X_validate)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "print(f'Mean Squared Error on Validate Set: {mse}')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBRegressor(), param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Retrain the model on the entire train dataset (train + validate) with the best hyperparameters\n",
    "best_xgb_model = XGBRegressor(**best_params)\n",
    "\n",
    "X_combined = pd.concat([X_train, X_validate], ignore_index=True)\n",
    "y_combined = pd.concat([y_train, y_validate], ignore_index=True)\n",
    "best_xgb_model.fit(X_combined, y_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1459 entries, 1461 to 2919\n",
      "Data columns (total 27 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   LotFrontage    1459 non-null   float64\n",
      " 1   LotArea        1459 non-null   int64  \n",
      " 2   OverallQual    1459 non-null   int64  \n",
      " 3   YearBuilt      1459 non-null   int64  \n",
      " 4   YearRemodAdd   1459 non-null   int64  \n",
      " 5   MasVnrArea     1459 non-null   float64\n",
      " 6   BsmtFinSF1     1459 non-null   int64  \n",
      " 7   BsmtUnfSF      1459 non-null   int64  \n",
      " 8   TotalBsmtSF    1459 non-null   int64  \n",
      " 9   1stFlrSF       1459 non-null   int64  \n",
      " 10  2ndFlrSF       1459 non-null   int64  \n",
      " 11  GrLivArea      1459 non-null   int64  \n",
      " 12  BsmtFullBath   1459 non-null   int64  \n",
      " 13  FullBath       1459 non-null   int64  \n",
      " 14  HalfBath       1459 non-null   int64  \n",
      " 15  BedroomAbvGr   1459 non-null   int64  \n",
      " 16  KitchenAbvGr   1459 non-null   int64  \n",
      " 17  TotRmsAbvGrd   1459 non-null   int64  \n",
      " 18  Fireplaces     1459 non-null   int64  \n",
      " 19  GarageYrBlt    1459 non-null   float64\n",
      " 20  GarageCars     1459 non-null   int64  \n",
      " 21  GarageArea     1459 non-null   int64  \n",
      " 22  WoodDeckSF     1459 non-null   int64  \n",
      " 23  OpenPorchSF    1459 non-null   int64  \n",
      " 24  EnclosedPorch  1459 non-null   int64  \n",
      " 25  ScreenPorch    1459 non-null   int64  \n",
      " 26  PoolArea       1459 non-null   int64  \n",
      "dtypes: float64(3), int64(24)\n",
      "memory usage: 319.2 KB\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data[test_data.columns[test_data.columns.isin(X_combined.columns)]]\n",
    "test_data.info()\n",
    "test_data['BsmtFinSF1'].astype('float64')\n",
    "test_data['BsmtUnfSF'].astype('float64')\n",
    "test_data['TotalBsmtSF'].astype('float64')\n",
    "test_data['BsmtFullBath'].astype('float64')\n",
    "y_test = best_xgb_model.predict(test_data)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Predicted_Sales_Price']\n",
    "y_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, can you run it on your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128218.39 , 151068.9  , 175290.16 , 185664.92 , 194694.75 ,\n",
       "       177672.94 , 168205.89 , 163902.75 , 181029.33 , 127697.125],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Retrain the model on the entire train dataset (train + validate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SalePrice  SalePrice\n",
      "Id                        \n",
      "893        True       True\n",
      "1106       True       True\n",
      "414        True       True\n",
      "523        True       True\n",
      "1037       True       True\n",
      "615        True       True\n",
      "219        True       True\n",
      "1161       True       True\n",
      "650        True       True\n",
      "888        True       True\n",
      "577        True       True\n",
      "1253       True       True\n",
      "1062       True       True\n",
      "568        True       True\n",
      "1109       True       True\n",
      "1114       True       True\n",
      "169        True       True\n",
      "1103       True       True\n",
      "1121       True       True\n",
      "68         True       True\n",
      "1041       True       True\n",
      "454        True       True\n",
      "671        True       True\n",
      "1095       True       True\n",
      "193        True       True\n",
      "124        True       True\n",
      "416        True       True\n",
      "278        True       True\n",
      "434        True       True\n",
      "1318       True       True\n",
      "185        True       True\n",
      "555        True       True\n",
      "1174       True       True\n",
      "77         True       True\n",
      "907        True       True\n",
      "675        True       True\n",
      "1399       True       True\n",
      "375        True       True\n",
      "1033       True       True\n",
      "260        True       True\n",
      "52         True       True\n",
      "245        True       True\n",
      "1102       True       True\n",
      "582        True       True\n",
      "680        True       True\n",
      "1133       True       True\n",
      "1221       True       True\n",
      "50         True       True\n",
      "592        True       True\n",
      "1270       True       True\n",
      "1250       True       True\n",
      "1139       True       True\n",
      "491        True       True\n",
      "1025       True       True\n",
      "812        True       True\n",
      "142        True       True\n",
      "847        True       True\n",
      "926        True       True\n",
      "773        True       True\n",
      "533        True       True\n",
      "30         True       True\n",
      "1300       True       True\n",
      "66         True       True\n",
      "766        True       True\n",
      "1348       True       True\n",
      "176        True       True\n",
      "395        True       True\n",
      "620        True       True\n",
      "1132       True       True\n",
      "116        True       True\n",
      "895        True       True\n",
      "1222       True       True\n",
      "428        True       True\n",
      "737        True       True\n",
      "899        True       True\n",
      "683        True       True\n",
      "991        True       True\n",
      "719        True       True\n",
      "45         True       True\n",
      "60         True       True\n",
      "364        True       True\n",
      "399        True       True\n",
      "423        True       True\n",
      "495        True       True\n",
      "417        True       True\n",
      "585        True       True\n",
      "271        True       True\n",
      "352        True       True\n",
      "1079       True       True\n",
      "1345       True       True\n",
      "837        True       True\n",
      "644        True       True\n",
      "275        True       True\n",
      "323        True       True\n",
      "79         True       True\n",
      "923        True       True\n",
      "276        True       True\n",
      "1266       True       True\n",
      "221        True       True\n",
      "317        True       True\n",
      "1007       True       True\n",
      "1241       True       True\n",
      "71         True       True\n",
      "16         True       True\n",
      "1165       True       True\n",
      "1321       True       True\n",
      "755        True       True\n",
      "721        True       True\n",
      "1048       True       True\n",
      "629        True       True\n",
      "637        True       True\n",
      "465        True       True\n",
      "856        True       True\n",
      "1398       True       True\n",
      "383        True       True\n",
      "1429       True       True\n",
      "789        True       True\n",
      "1341       True       True\n",
      "1217       True       True\n",
      "333        True       True\n",
      "544        True       True\n",
      "204        True       True\n",
      "1135       True       True\n",
      "1415       True       True\n",
      "430        True       True\n",
      "1273       True       True\n",
      "747        True       True\n",
      "590        True       True\n",
      "839        True       True\n",
      "1294       True       True\n",
      "591        True       True\n",
      "586        True       True\n",
      "1202       True       True\n",
      "199        True       True\n",
      "917        True       True\n",
      "995        True       True\n",
      "1229       True       True\n",
      "44         True       True\n",
      "1034       True       True\n",
      "692        True       True\n",
      "232        True       True\n",
      "527        True       True\n",
      "102        True       True\n",
      "1093       True       True\n",
      "412        True       True\n",
      "1393       True       True\n",
      "908        True       True\n",
      "783        True       True\n",
      "953        True       True\n",
      "621        True       True\n",
      "670        True       True\n",
      "129        True       True\n",
      "530        True       True\n",
      "911        True       True\n",
      "999        True       True\n",
      "1451       True       True\n",
      "1164       True       True\n",
      "248        True       True\n",
      "529        True       True\n",
      "734        True       True\n",
      "33         True       True\n",
      "635        True       True\n",
      "1028       True       True\n",
      "1054       True       True\n",
      "576        True       True\n",
      "844        True       True\n",
      "298        True       True\n",
      "262        True       True\n",
      "1047       True       True\n",
      "940        True       True\n",
      "310        True       True\n",
      "164        True       True\n",
      "1010       True       True\n",
      "600        True       True\n",
      "1176       True       True\n",
      "372        True       True\n",
      "240        True       True\n",
      "882        True       True\n",
      "1334       True       True\n",
      "1359       True       True\n",
      "1157       True       True\n",
      "813        True       True\n",
      "1332       True       True\n",
      "426        True       True\n",
      "1055       True       True\n",
      "64         True       True\n",
      "818        True       True\n",
      "1395       True       True\n",
      "1307       True       True\n",
      "916        True       True\n",
      "433        True       True\n",
      "694        True       True\n",
      "967        True       True\n",
      "1171       True       True\n",
      "1043       True       True\n",
      "608        True       True\n",
      "1090       True       True\n",
      "31         True       True\n",
      "57         True       True\n",
      "1179       True       True\n",
      "452        True       True\n",
      "559        True       True\n",
      "366        True       True\n",
      "424        True       True\n",
      "959        True       True\n",
      "807        True       True\n",
      "1134       True       True\n",
      "980        True       True\n",
      "355        True       True\n",
      "1357       True       True\n",
      "307        True       True\n",
      "797        True       True\n",
      "100        True       True\n",
      "756        True       True\n",
      "272        True       True\n",
      "241        True       True\n",
      "598        True       True\n",
      "947        True       True\n",
      "359        True       True\n",
      "985        True       True\n",
      "778        True       True\n",
      "708        True       True\n",
      "599        True       True\n",
      "875        True       True\n",
      "931        True       True\n",
      "340        True       True\n",
      "1280       True       True\n",
      "1433       True       True\n",
      "1042       True       True\n",
      "712        True       True\n",
      "1050       True       True\n",
      "311        True       True\n",
      "572        True       True\n",
      "918        True       True\n",
      "603        True       True\n",
      "290        True       True\n",
      "429        True       True\n",
      "1086       True       True\n",
      "209        True       True\n",
      "681        True       True\n",
      "354        True       True\n",
      "325        True       True\n",
      "238        True       True\n",
      "59         True       True\n",
      "1160       True       True\n",
      "536        True       True\n",
      "368        True       True\n",
      "696        True       True\n",
      "24         True       True\n",
      "108        True       True\n",
      "1431       True       True\n",
      "1019       True       True\n",
      "362        True       True\n",
      "1002       True       True\n",
      "539        True       True\n",
      "1422       True       True\n",
      "1178       True       True\n",
      "1292       True       True\n",
      "782        True       True\n",
      "1448       True       True\n",
      "775        True       True\n",
      "673        True       True\n",
      "234        True       True\n",
      "427        True       True\n",
      "197        True       True\n",
      "1227       True       True\n",
      "82         True       True\n",
      "1369       True       True\n",
      "1126       True       True\n",
      "112        True       True\n",
      "1244       True       True\n",
      "745        True       True\n",
      "938        True       True\n",
      "345        True       True\n",
      "1233       True       True\n",
      "866        True       True\n",
      "1089       True       True\n",
      "351        True       True\n",
      "589        True       True\n",
      "1428       True       True\n",
      "949        True       True\n",
      "1450       True       True\n",
      "990        True       True\n",
      "678        True       True\n",
      "479        True       True\n",
      "1272       True       True\n",
      "1411       True       True\n",
      "480        True       True\n",
      "1362       True       True\n",
      "803        True       True\n",
      "652        True       True\n",
      "723        True       True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_train == y_validate)\n",
    "#y_combined.head(100)\n",
    "# data_types_train = X_train.dtypes\n",
    "\n",
    "# # Apply the data types from the training set to the test set\n",
    "# test_data = test_data.astype(data_types_train)\n",
    "# y_test = xgb_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Can you score your solution offline and see how it does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:51:44.533388Z",
     "iopub.status.busy": "2022-10-17T08:51:44.533094Z",
     "iopub.status.idle": "2022-10-17T08:51:44.548515Z",
     "shell.execute_reply": "2022-10-17T08:51:44.547390Z",
     "shell.execute_reply.started": "2022-10-17T08:51:44.533360Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in the ground truth file\n",
    "solution   = pd.read_csv(<your solution file>)\n",
    "y_true     = solution[\"SalePrice\"]\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "RMSLE = np.sqrt( mean_squared_log_error(y_true, predictions) )\n",
    "print(\"The score is %.5f\" % RMSLE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the below block to prepare your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:06.964744Z",
     "iopub.status.busy": "2022-10-17T08:50:06.964340Z",
     "iopub.status.idle": "2022-10-17T08:50:06.977852Z",
     "shell.execute_reply": "2022-10-17T08:50:06.976712Z",
     "shell.execute_reply.started": "2022-10-17T08:50:06.964712Z"
    }
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"Id\":test_data.index, \"SalePrice\":predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Feature importance</center>\n",
    "Let us also take a very quick look at the feature importance too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:06.980369Z",
     "iopub.status.busy": "2022-10-17T08:50:06.979530Z",
     "iopub.status.idle": "2022-10-17T08:50:07.282871Z",
     "shell.execute_reply": "2022-10-17T08:50:07.281929Z",
     "shell.execute_reply.started": "2022-10-17T08:50:06.980309Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plot_importance(regressor, max_num_features=8, ax=ax)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where here the `F score` is a measure \"*...based on the number of times a variable is selected for splitting, weighted by the squared improvement to the model as a result of each split, and averaged over all trees*.\" [1] \n",
    "\n",
    "Note that these importances are susceptible to small changes in the training data, and it is much better to make use of [\"GPU accelerated SHAP values\"](https://www.kaggle.com/carlmcbrideellis/gpu-accelerated-shap-values-jane-street-example), incorporated with version 1.3 of XGBoost.\n",
    "\n",
    "Can you follow the above guide use SHAP values instead of F Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Appendix: The RMSLE evaluation metric</center>\n",
    "From the competition [evaluation page](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) we see that the metric we are using is the root mean squared logarithmic error (RMSLE), which is given by\n",
    "\n",
    "$$ {\\mathrm {RMSLE}}\\,(y, \\hat y) = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2} $$\n",
    "\n",
    "where $\\hat{y}_i$ is the predicted value of the target for instance $i$, and $y_i$\n",
    "is the actual value of the target for instance $i$.\n",
    "\n",
    "It is important to note that, unlike the RMSE, the RMSLE is asymmetric; penalizing much more the underestimated predictions than the overestimated predictions. For example, say the correct value is $y_i = 1000$, then underestimating by 600 is almost twice as bad as overestimating by 600:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:07.284616Z",
     "iopub.status.busy": "2022-10-17T08:50:07.284340Z",
     "iopub.status.idle": "2022-10-17T08:50:07.290854Z",
     "shell.execute_reply": "2022-10-17T08:50:07.289987Z",
     "shell.execute_reply.started": "2022-10-17T08:50:07.284584Z"
    }
   },
   "outputs": [],
   "source": [
    "def RSLE(y_hat,y):\n",
    "    return np.sqrt((np.log1p(y_hat) - np.log1p(y))**2)\n",
    "\n",
    "print(\"The RMSLE score is %.3f\" % RSLE( 400,1000) )\n",
    "print(\"The RMSLE score is %.3f\" % RSLE(1600,1000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asymmetry arises because \n",
    "\n",
    "$$ \\log (1 + \\hat{y}_i) - \\log (1 + y_i) =  \\log \\left( \\frac{1 + \\hat{y}_i}{1 + y_i} \\right) $$\n",
    "\n",
    "so we are essentially looking at ratios, rather than differences such as is the case of the RMSE. We can see the form that this asymmetry takes in the following plot, again using 1000 as our ground truth value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:07.292446Z",
     "iopub.status.busy": "2022-10-17T08:50:07.292191Z",
     "iopub.status.idle": "2022-10-17T08:50:07.467273Z",
     "shell.execute_reply": "2022-10-17T08:50:07.466163Z",
     "shell.execute_reply.started": "2022-10-17T08:50:07.292407Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7, 4)\n",
    "x = np.linspace(5,4000,100)\n",
    "plt.plot(x, RSLE(x,1000))\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
